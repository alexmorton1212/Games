{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools as iter\n",
    "import json\n",
    "from json import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read In Master Word Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_df = pd.read_csv('WordLists/letterase-my-word-list.txt', sep=\"\\t\")\n",
    "single_df = words_df[['Word','Start1','End1']].rename(columns = {\"Word\":\"words\", \"Start1\":\"start\", \"End1\":\"end\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUNTIME: 2 MINUTES (OR LESS) UNDER CURRENT PARAMETERS\n",
    "\n",
    "seed = 12\n",
    "\n",
    "# SINGLE LETTER RESULTS IN 125,000 SOLUTIONS\n",
    "\n",
    "p1 = 0.10\n",
    "p2 = 0.008"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONDUCT FIRST MERGE AND SAMPLE BASED ON PROBABILITIES\n",
    "\n",
    "renamed_columns_1 = {\"words_x\":\"w1\", \"start_x\":\"start1\", \"end_x\":\"end1\", \"words_y\":\"w2\", \"start_y\":\"start2\", \"end_y\":\"end2\"}\n",
    "\n",
    "merge_df_1 = pd.merge(single_df, single_df, left_on = 'end', right_on = 'start').rename(columns = renamed_columns_1)\n",
    "counts_df_1 = merge_df_1['end1'].value_counts().reset_index()\n",
    "counts_df_1['p'] = (1/len(counts_df_1)) / counts_df_1['count']\n",
    "counts_merge_df_1 = pd.merge(merge_df_1, counts_df_1, left_on = 'end1', right_on = 'end1', how='left')\n",
    "counts_merge_df_1 = counts_merge_df_1[['w1','w2','start2','end2','p']]\n",
    "first_df = counts_merge_df_1.sample(n=round(len(counts_merge_df_1)*p1), random_state=seed, weights='p')\n",
    "first_df = first_df[['w1','w2','end2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONDUCT SECOND MERGE AND SAMPLE BASED ON PROBABILITIES\n",
    "\n",
    "renamed_columns_2 = {\"words\":\"w3\", \"start\":\"start3\", \"end\":\"end3\"}\n",
    "\n",
    "merge_df_2 = pd.merge(first_df, single_df, left_on = 'end2', right_on = 'start').rename(columns = renamed_columns_2)\n",
    "counts_df_2 = merge_df_2['end2'].value_counts().reset_index()\n",
    "counts_df_2['p'] = (1/len(counts_df_2)) / counts_df_2['count']\n",
    "counts_merge_df_2 = pd.merge(merge_df_2, counts_df_2, left_on = 'end2', right_on = 'end2', how='left')\n",
    "counts_merge_df_2 = counts_merge_df_2[['w1','w2','w3','start3','end3','p']]\n",
    "second_df = counts_merge_df_2.sample(n=round(len(counts_merge_df_2)*p2), random_state=seed, weights='p')\n",
    "second_df = second_df[['w1','w2','w3','end3']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONDUCT THIRD MERGE AND SAMPLE BASED ON PROBABILITIES\n",
    "\n",
    "renamed_columns_3 = {\"words\":\"w4\", \"start\":\"start4\", \"end\":\"end4\"}\n",
    "\n",
    "merge_df_3 = pd.merge(second_df, single_df, left_on = 'end3', right_on = 'start').rename(columns = renamed_columns_3)\n",
    "counts_df_3 = merge_df_3['end3'].value_counts().reset_index()\n",
    "counts_df_3['p'] = (1/len(counts_df_3)) / counts_df_3['count']\n",
    "counts_merge_df_3 = pd.merge(merge_df_3, counts_df_3, left_on = 'end3', right_on = 'end3', how='left')\n",
    "counts_merge_df_3 = counts_merge_df_3[['w1','w2','w3','w4','start4','end4','p']]\n",
    "third_df = counts_merge_df_3.sample(n=round(len(counts_merge_df_3)*p2), random_state=seed, weights='p')\n",
    "third_df = third_df[['w1','w2','w3','w4','end4']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONDUCT FINAL MERGE AND SAMPLE BASED ON PROBABILITIES\n",
    "\n",
    "renamed_columns_4 = {\"words\":\"w5\", \"start\":\"start5\", \"end\":\"end5\"}\n",
    "\n",
    "merge_df_4 = pd.merge(third_df, single_df, left_on = 'end4', right_on = 'start').rename(columns = renamed_columns_4)\n",
    "counts_df_4 = merge_df_4['end4'].value_counts().reset_index()\n",
    "counts_df_4['p'] = (1/len(counts_df_4)) / counts_df_4['count']\n",
    "counts_merge_df_4 = pd.merge(merge_df_4, counts_df_4, left_on = 'end4', right_on = 'end4', how='left')\n",
    "counts_merge_df_4 = counts_merge_df_4[['w1','w2','w3','w4','w5','start5','end5','p']]\n",
    "final_df = counts_merge_df_4.sample(n=round(len(counts_merge_df_4)*p2), random_state=seed, weights='p')\n",
    "final_df = final_df[['w1','w2','w3','w4','w5']]\n",
    "\n",
    "# REMOVE ROWS WITH DUPLICATES\n",
    "\n",
    "final_df = final_df[~final_df.apply(lambda x: x.duplicated().any(), axis=1)]\n",
    "\n",
    "# FORMAT FINAL DATAFRAME\n",
    "\n",
    "renamed_columns_final = {\"w1\":\"words_1\", \"w2\":\"words_2\", \"w3\":\"words_3\", \"w4\":\"words_4\", \"w5\":\"words_5\"}\n",
    "final_df = final_df.rename(columns = renamed_columns_final).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Solution Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPORT SOLUTIONS\n",
    "\n",
    "result = final_df.to_json(orient=\"index\")\n",
    "output_data = 'single_data.json'\n",
    "\n",
    "with open(output_data, 'w') as f:\n",
    "    dump(result, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Word List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv(\"WordLists/letterase-my-word-list.txt\", sep=\"\\t\")['Word'].tolist()\n",
    "words_upper = [s.upper() for s in words]\n",
    "json_string = json.dumps(words_upper)\n",
    "\n",
    "with open(\"single_word_list.json\", \"w\") as f:\n",
    "    json.dump(words_upper, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
